env_name: PandaRearrangeBimanual-v0
env_kwargs: 
  render: False
  task_kwargs:
    goal_z: 0.2
    obj_xyz_range: [0.3, 0.4, 0]
    num_blocks: 1 # number of blocks
    os_rate: 0.5 # init goal in different table
    os_num_dist: binominal # other side number distribution 'uniform', 'binominal'
    obj_in_hand_rate: 1 # init obj in hand
    gap_distance: null # if None, auto set
    debug_mode: False # if show debug info
    base_ep_len: 50
n_epochs: 100
n_cycles: 100
n_batches: 40
save_interval: 5
seed: 123
num_workers: 16
replay_strategy: future
clip_return: 50
noise_eps: 0.2
random_eps: 0.3
exp_schedule: null
buffer_size: 1000000
replay_k: 4
clip_obs: 200
batch_size: 2048  # 256 * 8. MPI version had effectively a larger batch size due to multiple workers.
gamma: 0.98
action_l2: 1

# network
defaults:
  - actor: mlp
  - critic: mlp
optim_actor:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0
optim_critic:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0
warmup_actor: 0
warmup_critic: 0

polyak: 0.95
n_test_eps: 100
clip_range: 5
demo_length: 20
cuda: True
num_rollouts: 1
init_trajs: null
n_init_steps: 0
norm_reward: False
min_samples: 0
r_scale: 1
ckpt_path: ./checkpoint.pkl
render_interval: 10

# wandb
wandb: True
project: debug
name: foo
wid: null